{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import psycopg2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Deal with issuesCheckpoint_Graphviz"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "input_directory = \"/path/to/input/json/files\"\n",
    "output_directory = \"/path/to/output/json/files\"\n",
    "\n",
    "for filename in os.listdir(input_directory):\n",
    "    if filename.endswith(\".json\"):\n",
    "        input_filepath = os.path.join(input_directory, filename)\n",
    "        output_filepath_no_links = os.path.join(output_directory, f\"{filename}_no_links.json\")\n",
    "        output_filepath_with_links = os.path.join(output_directory, f\"{filename}_with_links.json\")\n",
    "\n",
    "        with open(input_filepath, \"r\") as input_file:\n",
    "            data = json.load(input_file)\n",
    "\n",
    "        # Extract the \"linkedCommits\" and remove it from the original data\n",
    "        linked_commits = data[\"record\"].pop(\"linkedCommits\", [])\n",
    "\n",
    "        # Write the data without \"linkedCommits\" to a separate file\n",
    "        with open(output_filepath_no_links, \"w\") as output_file:\n",
    "            json.dump(data, output_file, indent=4)\n",
    "\n",
    "        # Create a new dictionary with \"linkedCommits\" and \"id\" as primary key\n",
    "        new_data = {\n",
    "            \"id\": data[\"id\"],\n",
    "            \"linkedCommits\": linked_commits\n",
    "        }\n",
    "\n",
    "        # Write the data with \"linkedCommits\" and \"id\" to a separate file\n",
    "        with open(output_filepath_with_links, \"w\") as output_file:\n",
    "            json.dump(new_data, output_file, indent=4)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# split the file into with_link and no_link tables\n",
    "import json\n",
    "import os\n",
    "\n",
    "input_directory = \"/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data\"\n",
    "output_directory = \"/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/split data\"\n",
    "\n",
    "for filename in os.listdir(input_directory):\n",
    "    if filename.startswith(\"issue_\") and filename.endswith(\".json\"):\n",
    "        input_filepath = os.path.join(input_directory, filename)\n",
    "        output_filepath_no_links = os.path.join(output_directory, f\"{filename}_no_links.json\")\n",
    "        output_filepath_with_links = os.path.join(output_directory, f\"{filename}_with_links.json\")\n",
    "\n",
    "        with open(input_filepath, \"r\") as input_file:\n",
    "            data = json.load(input_file)\n",
    "\n",
    "        # Extract the \"linkedCommits\" and remove it from the original data\n",
    "        linked_commits = data[\"record\"].pop(\"linkedCommits\", [])\n",
    "\n",
    "        # Write the data without \"linkedCommits\" to a separate file\n",
    "        with open(output_filepath_no_links, \"w\") as output_file:\n",
    "            json.dump(data, output_file, indent=4)\n",
    "\n",
    "        # Create a new dictionary with \"linkedCommits\" and \"id\" as primary key\n",
    "        new_data = {\n",
    "            \"id\": data[\"id\"],\n",
    "            \"linkedCommits\": linked_commits\n",
    "        }\n",
    "\n",
    "        # Write the data with \"linkedCommits\" and \"id\" to a separate file\n",
    "        with open(output_filepath_with_links, \"w\") as output_file:\n",
    "            json.dump(new_data, output_file, indent=4)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred while inserting data: duplicate key value violates unique constraint \"json_no_links_pkey\"\n",
      "DETAIL:  Key (id)=(1976) already exists.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# insert into json_no_link table\n",
    "\n",
    "import os\n",
    "import json\n",
    "import psycopg2\n",
    "\n",
    "connection_params = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5432\",\n",
    "    \"database\": \"issuesCheckpoint_Graphviz\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"Wuzhonghao0313!\"\n",
    "}\n",
    "\n",
    "json_directory = \"/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/split data\"\n",
    "\n",
    "conn = psycopg2.connect(**connection_params)\n",
    "cur = conn.cursor()\n",
    "\n",
    "try:\n",
    "    for filename in os.listdir(json_directory):\n",
    "        if filename.endswith(\"_no_links.json\"):\n",
    "            filepath = os.path.join(json_directory, filename)\n",
    "            with open(filepath, \"r\") as file:\n",
    "                data = json.load(file)\n",
    "\n",
    "            id = int(filename.split(\"_\")[1].split(\".\")[0])\n",
    "            record = data[\"record\"]\n",
    "\n",
    "            # Extract the timestamp values and handle empty strings\n",
    "            created = record.get(\"created\") or None\n",
    "            resolved = record.get(\"resolved\") or None\n",
    "\n",
    "            # Remove the 'Z' character from the timestamp strings\n",
    "            created = created.rstrip('Z') if created else None\n",
    "            resolved = resolved.rstrip('Z') if resolved else None\n",
    "\n",
    "            query = \"\"\"\n",
    "            INSERT INTO json_no_links (id, url, summary, description, type, priority, status, resolution, created, resolved, labels, versions, fixVersions, comments)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, TO_TIMESTAMP(%s, 'YYYY-MM-DDTHH24:MI:SS.US'), TO_TIMESTAMP(%s, 'YYYY-MM-DDTHH24:MI:SS.US'), %s, %s, %s, %s)\n",
    "            \"\"\"\n",
    "            values = (\n",
    "                id,\n",
    "                record.get(\"url\"),\n",
    "                record.get(\"summary\"),\n",
    "                record.get(\"description\"),\n",
    "                record.get(\"type\"),\n",
    "                record.get(\"priority\"),\n",
    "                record.get(\"status\"),\n",
    "                record.get(\"resolution\"),\n",
    "                created,\n",
    "                resolved,\n",
    "                json.dumps(record.get(\"labels\")),\n",
    "                json.dumps(record.get(\"versions\")),\n",
    "                json.dumps(record.get(\"fixVersions\")),\n",
    "                json.dumps(record.get(\"comments\"))\n",
    "            )\n",
    "\n",
    "            cur.execute(query, values)\n",
    "\n",
    "    conn.commit()\n",
    "    print(\"Data inserted successfully!\")\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    conn.rollback()\n",
    "    print(\"Error occurred while inserting data:\", e)\n",
    "\n",
    "finally:\n",
    "    cur.close()\n",
    "    conn.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# split the with_link json files\n",
    "import json\n",
    "import os\n",
    "\n",
    "def split_json_files(filename, output_directory):\n",
    "    with open(filename, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Iterate over the linked commits and create separate files\n",
    "    for index, commit in enumerate(data['linkedCommits']):\n",
    "        primary_id = data['id']\n",
    "        linked_id = commit['id']\n",
    "\n",
    "        # Create the output file name using both primary and linked IDs\n",
    "        output_filename = f\"{primary_id}_{linked_id}.json\"\n",
    "        output_filepath = os.path.join(output_directory, output_filename)\n",
    "\n",
    "        # Write the linked commit data to a separate JSON file\n",
    "        with open(output_filepath, 'w') as output_file:\n",
    "            json.dump(commit, output_file, indent=4)\n",
    "\n",
    "# Specify the input directory\n",
    "input_directory = '/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/split data'\n",
    "# Specify the output directory\n",
    "output_directory = '/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/split data/split link commits'\n",
    "\n",
    "# Iterate over the files in the input directory\n",
    "for filename in os.listdir(input_directory):\n",
    "    if filename.startswith(\"issue_\") and filename.endswith(\"json_with_links.json\"):\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(input_directory, filename)\n",
    "        # Split the JSON file and save the linked commits to the output directory\n",
    "        split_json_files(file_path, output_directory)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The encoding of the JSON file is: ascii\n"
     ]
    }
   ],
   "source": [
    "import chardet\n",
    "import json\n",
    "\n",
    "def detect_encoding(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        raw_data = file.read()\n",
    "        result = chardet.detect(raw_data)\n",
    "        encoding = result['encoding']\n",
    "        return encoding\n",
    "\n",
    "# Provide the path to your JSON file\n",
    "json_file_path = '/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/split data/split link commits/14_2577.json'\n",
    "\n",
    "# Detect the encoding\n",
    "encoding = detect_encoding(json_file_path)\n",
    "\n",
    "# Print the detected encoding\n",
    "print(f\"The encoding of the JSON file is: {encoding}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Invalid JSON file: /Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/split data/split link commits/.DS_Store\n",
      "Data inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "# insert into json_with_link table, exclude versionTags and changes\n",
    "\n",
    "connection_params = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5432\",\n",
    "    \"database\": \"issuesCheckpoint_Graphviz\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"Wuzhonghao0313!\"\n",
    "}\n",
    "\n",
    "json_directory = \"/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/split data/split link commits\"\n",
    "\n",
    "conn = psycopg2.connect(**connection_params)\n",
    "cur = conn.cursor()\n",
    "\n",
    "try:\n",
    "    for filename in os.listdir(json_directory):\n",
    "            filepath = os.path.join(json_directory, filename)\n",
    "            with open(filepath, \"r\", encoding=\"ascii\", errors=\"ignore\") as file:\n",
    "                try:\n",
    "                    data = json.load(file)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Error: Invalid JSON file: {filepath}\")\n",
    "                    continue\n",
    "\n",
    "            # Split the filename by underscore\n",
    "            ids = filename.split('_')\n",
    "            # Extract the primary ID and linked ID\n",
    "            primary_id = ids[0]\n",
    "\n",
    "            # Extract the timestamp values and handle empty strings\n",
    "            created = data.get(\"created\") or None\n",
    "\n",
    "            # Remove the 'Z' character from the timestamp strings\n",
    "            created = created.rstrip('Z') if created else None\n",
    "\n",
    "            query = \"\"\" INSERT INTO json_with_links (id, linked_id, summary, description, status, url, sha, created, merged, labels)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, TO_TIMESTAMP(%s, 'YYYY-MM-DDTHH24:MI:SS.US'),  %s, %s)\n",
    "            \"\"\"\n",
    "            values = (\n",
    "                primary_id,\n",
    "                data.get(\"id\"),\n",
    "                data.get(\"summary\"),\n",
    "                data.get(\"description\"),\n",
    "                data.get(\"status\"),\n",
    "                data.get(\"url\"),\n",
    "                data.get(\"sha\"),\n",
    "                created,\n",
    "                data.get(\"merged\"),\n",
    "                json.dumps(data.get(\"labels\"))\n",
    "            )\n",
    "\n",
    "            cur.execute(query, values)\n",
    "\n",
    "    conn.commit()\n",
    "    print(\"Data inserted successfully!\")\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    conn.rollback()\n",
    "    print(\"Error occurred while inserting data:\", e)\n",
    "\n",
    "finally:\n",
    "    cur.close()\n",
    "    conn.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Invalid JSON file: /Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/split data/split link commits/.DS_Store\n",
      "Data inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "# insert into versionTags table, in total 3 columns\n",
    "import json\n",
    "import psycopg2\n",
    "import os\n",
    "\n",
    "connection_params = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5432\",\n",
    "    \"database\": \"issuesCheckpoint_Graphviz\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"Wuzhonghao0313!\"\n",
    "}\n",
    "\n",
    "json_directory = \"/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/split data/split link commits\"\n",
    "\n",
    "conn = psycopg2.connect(**connection_params)\n",
    "cur = conn.cursor()\n",
    "\n",
    "try:\n",
    "    for filename in os.listdir(json_directory):\n",
    "        filepath = os.path.join(json_directory, filename)\n",
    "        with open(filepath, \"r\", encoding=\"ascii\", errors=\"ignore\") as file:\n",
    "            try:\n",
    "                data = json.load(file)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error: Invalid JSON file: {filepath}\")\n",
    "                continue\n",
    "\n",
    "        # Extract versionTags and find the biggest versionTag\n",
    "        version_tags = data.get(\"versionTags\") or []\n",
    "        biggest_version_tag = max(version_tags) if version_tags else None\n",
    "\n",
    "        # Insert data into the new table for versionTags\n",
    "        version_tags_query = \"\"\"\n",
    "        INSERT INTO versionTags (linked_id, versionTags, newest_version)\n",
    "        VALUES (%s, %s, %s)\n",
    "        \"\"\"\n",
    "        version_tags_values = (\n",
    "            data.get(\"id\"),\n",
    "            json.dumps(version_tags),\n",
    "            biggest_version_tag\n",
    "        )\n",
    "\n",
    "        cur.execute(version_tags_query, version_tags_values)\n",
    "\n",
    "    conn.commit()\n",
    "    print(\"Data inserted successfully!\")\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    conn.rollback()\n",
    "    print(\"Error occurred while inserting data:\", e)\n",
    "\n",
    "finally:\n",
    "    cur.close()\n",
    "    conn.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Invalid JSON file: /Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/split data/split link commits/.DS_Store\n",
      "Data inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "# insert into changes table\n",
    "import psycopg2\n",
    "import json\n",
    "import os\n",
    "\n",
    "connection_params = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5432\",\n",
    "    \"database\": \"issuesCheckpoint_Graphviz\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"Wuzhonghao0313!\"\n",
    "}\n",
    "\n",
    "json_directory = \"/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/split data/split link commits\"\n",
    "\n",
    "conn = psycopg2.connect(**connection_params)\n",
    "cur = conn.cursor()\n",
    "\n",
    "try:\n",
    "    for filename in os.listdir(json_directory):\n",
    "        filepath = os.path.join(json_directory, filename)\n",
    "        with open(filepath, \"r\", encoding=\"ascii\", errors=\"ignore\") as file:\n",
    "            try:\n",
    "                data = json.load(file)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error: Invalid JSON file: {filepath}\")\n",
    "                continue\n",
    "\n",
    "        changes = data.get(\"changes\", [])\n",
    "        for change in changes:\n",
    "            query = \"\"\"\n",
    "            INSERT INTO changes (linked_id, before, after)\n",
    "            VALUES (%s, %s, %s)\n",
    "            \"\"\"\n",
    "            values = (\n",
    "                data.get(\"id\"),\n",
    "                change.get(\"before\"),\n",
    "                change.get(\"after\")\n",
    "            )\n",
    "            cur.execute(query, values)\n",
    "\n",
    "    conn.commit()\n",
    "    print(\"Data inserted successfully!\")\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    conn.rollback()\n",
    "    print(\"Error occurred while inserting data:\", e)\n",
    "\n",
    "finally:\n",
    "    cur.close()\n",
    "    conn.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Deal with issuesCheckpoint_Inkscape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split JSON files saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# split the json file\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Set the current working directory\n",
    "os.chdir('/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data')\n",
    "\n",
    "# Load the nested JSON file\n",
    "with open('issuesCheckpoint_Inkscape.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Create a directory to store the split JSON files\n",
    "output_directory = '/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/issuesCheckpoint_Inkscape_split'\n",
    "\n",
    "# Iterate over each issue and save it as a separate JSON file\n",
    "for issue in data['issues']:\n",
    "    issue_id = issue['id']\n",
    "    filename = f'issue_{issue_id}.json'\n",
    "    output_filepath = os.path.join(output_directory, filename)\n",
    "    with open(output_filepath, 'w') as outfile:\n",
    "        json.dump(issue, outfile, indent=4)\n",
    "    # print(f'Saved {filename} to {output_directory}')\n",
    "\n",
    "print('Split JSON files saved successfully.')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split JSON files saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# split the file into with_link and no_link tables\n",
    "import json\n",
    "import os\n",
    "\n",
    "input_directory = \"/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/issuesCheckpoint_Inkscape_split\"\n",
    "output_directory = \"/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/issuesCheckpoint_Inkscape_split/split data\"\n",
    "\n",
    "for filename in os.listdir(input_directory):\n",
    "    if filename.startswith(\"issue_\") and filename.endswith(\".json\"):\n",
    "        input_filepath = os.path.join(input_directory, filename)\n",
    "        output_filepath_no_links = os.path.join(output_directory, f\"{filename}_no_links.json\")\n",
    "        output_filepath_with_links = os.path.join(output_directory, f\"{filename}_with_links.json\")\n",
    "\n",
    "        with open(input_filepath, \"r\") as input_file:\n",
    "            data = json.load(input_file)\n",
    "\n",
    "        # Extract the \"linkedCommits\" and remove it from the original data\n",
    "        linked_commits = data[\"record\"].pop(\"linkedCommits\", [])\n",
    "\n",
    "        # Write the data without \"linkedCommits\" to a separate file\n",
    "        with open(output_filepath_no_links, \"w\") as output_file:\n",
    "            json.dump(data, output_file, indent=4)\n",
    "\n",
    "        # Create a new dictionary with \"linkedCommits\" and \"id\" as primary key\n",
    "        new_data = {\n",
    "            \"id\": data[\"id\"],\n",
    "            \"linkedCommits\": linked_commits\n",
    "        }\n",
    "\n",
    "        # Write the data with \"linkedCommits\" and \"id\" to a separate file\n",
    "        with open(output_filepath_with_links, \"w\") as output_file:\n",
    "            json.dump(new_data, output_file, indent=4)\n",
    "\n",
    "print('Split JSON files saved successfully.')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "# insert into json_no_link table\n",
    "\n",
    "import os\n",
    "import json\n",
    "import psycopg2\n",
    "\n",
    "connection_params = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5432\",\n",
    "    \"database\": \"issuesCheckpoint_Inkscape\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"Wuzhonghao0313!\"\n",
    "}\n",
    "\n",
    "json_directory = \"/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/issuesCheckpoint_Inkscape_split/split data\"\n",
    "\n",
    "conn = psycopg2.connect(**connection_params)\n",
    "cur = conn.cursor()\n",
    "\n",
    "try:\n",
    "    for filename in os.listdir(json_directory):\n",
    "        if filename.endswith(\"_no_links.json\"):\n",
    "            filepath = os.path.join(json_directory, filename)\n",
    "            with open(filepath, \"r\") as file:\n",
    "                data = json.load(file)\n",
    "\n",
    "            id = int(filename.split(\"_\")[1].split(\".\")[0])\n",
    "            record = data[\"record\"]\n",
    "\n",
    "            # Extract the timestamp values and handle empty strings\n",
    "            created = record.get(\"created\") or None\n",
    "            resolved = record.get(\"resolved\") or None\n",
    "\n",
    "            # Remove the 'Z' character from the timestamp strings\n",
    "            created = created.rstrip('Z') if created else None\n",
    "            resolved = resolved.rstrip('Z') if resolved else None\n",
    "\n",
    "            query = \"\"\"\n",
    "            INSERT INTO json_no_links (id, url, summary, description, type, priority, status, resolution, created, resolved, labels, versions, fixVersions, comments)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, TO_TIMESTAMP(%s, 'YYYY-MM-DDTHH24:MI:SS.US'), TO_TIMESTAMP(%s, 'YYYY-MM-DDTHH24:MI:SS.US'), %s, %s, %s, %s)\n",
    "            \"\"\"\n",
    "            values = (\n",
    "                id,\n",
    "                record.get(\"url\"),\n",
    "                record.get(\"summary\"),\n",
    "                record.get(\"description\"),\n",
    "                record.get(\"type\"),\n",
    "                record.get(\"priority\"),\n",
    "                record.get(\"status\"),\n",
    "                record.get(\"resolution\"),\n",
    "                created,\n",
    "                resolved,\n",
    "                json.dumps(record.get(\"labels\")),\n",
    "                json.dumps(record.get(\"versions\")),\n",
    "                json.dumps(record.get(\"fixVersions\")),\n",
    "                json.dumps(record.get(\"comments\"))\n",
    "            )\n",
    "\n",
    "            cur.execute(query, values)\n",
    "\n",
    "    conn.commit()\n",
    "    print(\"Data inserted successfully!\")\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    conn.rollback()\n",
    "    print(\"Error occurred while inserting data:\", e)\n",
    "\n",
    "finally:\n",
    "    cur.close()\n",
    "    conn.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# split the with_link json files\n",
    "import json\n",
    "import os\n",
    "\n",
    "def split_json_files(filename, output_directory):\n",
    "    with open(filename, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Iterate over the linked commits and create separate files\n",
    "    for index, commit in enumerate(data['linkedCommits']):\n",
    "        primary_id = data['id']\n",
    "        linked_id = commit['id']\n",
    "\n",
    "        # Create the output file name using both primary and linked IDs\n",
    "        output_filename = f\"{primary_id}_{linked_id}.json\"\n",
    "        output_filepath = os.path.join(output_directory, output_filename)\n",
    "\n",
    "        # Write the linked commit data to a separate JSON file\n",
    "        with open(output_filepath, 'w') as output_file:\n",
    "            json.dump(commit, output_file, indent=4)\n",
    "\n",
    "# Specify the input directory\n",
    "input_directory = '/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/issuesCheckpoint_Inkscape_split/split data'\n",
    "# Specify the output directory\n",
    "output_directory = '/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/issuesCheckpoint_Inkscape_split/split data/split link commits'\n",
    "\n",
    "# Iterate over the files in the input directory\n",
    "for filename in os.listdir(input_directory):\n",
    "    if filename.startswith(\"issue_\") and filename.endswith(\"json_with_links.json\"):\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(input_directory, filename)\n",
    "        # Split the JSON file and save the linked commits to the output directory\n",
    "        split_json_files(file_path, output_directory)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The encoding of the JSON file is: ascii\n"
     ]
    }
   ],
   "source": [
    "import chardet\n",
    "import json\n",
    "\n",
    "def detect_encoding(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        raw_data = file.read()\n",
    "        result = chardet.detect(raw_data)\n",
    "        encoding = result['encoding']\n",
    "        return encoding\n",
    "\n",
    "# Provide the path to your JSON file\n",
    "json_file_path = '/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/issuesCheckpoint_Inkscape_split/split data/split link commits/1_1080.json'\n",
    "\n",
    "# Detect the encoding\n",
    "encoding = detect_encoding(json_file_path)\n",
    "\n",
    "# Print the detected encoding\n",
    "print(f\"The encoding of the JSON file is: {encoding}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "# insert into json_with_link table, exclude versionTags and changes\n",
    "\n",
    "connection_params = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5432\",\n",
    "    \"database\": \"issuesCheckpoint_Inkscape\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"Wuzhonghao0313!\"\n",
    "}\n",
    "\n",
    "json_directory = \"/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/issuesCheckpoint_Inkscape_split/split data/split link commits\"\n",
    "\n",
    "conn = psycopg2.connect(**connection_params)\n",
    "cur = conn.cursor()\n",
    "\n",
    "try:\n",
    "    for filename in os.listdir(json_directory):\n",
    "            filepath = os.path.join(json_directory, filename)\n",
    "            with open(filepath, \"r\", encoding=\"ascii\", errors=\"ignore\") as file:\n",
    "                try:\n",
    "                    data = json.load(file)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Error: Invalid JSON file: {filepath}\")\n",
    "                    continue\n",
    "\n",
    "            # Split the filename by underscore\n",
    "            ids = filename.split('_')\n",
    "            # Extract the primary ID and linked ID\n",
    "            primary_id = ids[0]\n",
    "\n",
    "            # Extract the timestamp values and handle empty strings\n",
    "            created = data.get(\"created\") or None\n",
    "\n",
    "            # Remove the 'Z' character from the timestamp strings\n",
    "            created = created.rstrip('Z') if created else None\n",
    "\n",
    "            query = \"\"\" INSERT INTO json_with_links (id, linked_id, summary, description, status, url, sha, created, merged, labels)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, TO_TIMESTAMP(%s, 'YYYY-MM-DDTHH24:MI:SS.US'),  %s, %s)\n",
    "            \"\"\"\n",
    "            values = (\n",
    "                primary_id,\n",
    "                data.get(\"id\"),\n",
    "                data.get(\"summary\"),\n",
    "                data.get(\"description\"),\n",
    "                data.get(\"status\"),\n",
    "                data.get(\"url\"),\n",
    "                data.get(\"sha\"),\n",
    "                created,\n",
    "                data.get(\"merged\"),\n",
    "                json.dumps(data.get(\"labels\"))\n",
    "            )\n",
    "\n",
    "            cur.execute(query, values)\n",
    "\n",
    "    conn.commit()\n",
    "    print(\"Data inserted successfully!\")\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    conn.rollback()\n",
    "    print(\"Error occurred while inserting data:\", e)\n",
    "\n",
    "finally:\n",
    "    cur.close()\n",
    "    conn.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "# insert into versionTags table, in total 3 columns\n",
    "import json\n",
    "import psycopg2\n",
    "import os\n",
    "\n",
    "connection_params = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5432\",\n",
    "    \"database\": \"issuesCheckpoint_Inkscape\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"Wuzhonghao0313!\"\n",
    "}\n",
    "\n",
    "json_directory = \"/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/issuesCheckpoint_Inkscape_split/split data/split link commits\"\n",
    "\n",
    "conn = psycopg2.connect(**connection_params)\n",
    "cur = conn.cursor()\n",
    "\n",
    "try:\n",
    "    for filename in os.listdir(json_directory):\n",
    "        filepath = os.path.join(json_directory, filename)\n",
    "        with open(filepath, \"r\", encoding=\"ascii\", errors=\"ignore\") as file:\n",
    "            try:\n",
    "                data = json.load(file)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error: Invalid JSON file: {filepath}\")\n",
    "                continue\n",
    "\n",
    "        # Extract versionTags and find the biggest versionTag\n",
    "        version_tags = data.get(\"versionTags\") or []\n",
    "        biggest_version_tag = max(version_tags) if version_tags else None\n",
    "\n",
    "        # Insert data into the new table for versionTags\n",
    "        version_tags_query = \"\"\"\n",
    "        INSERT INTO versionTags (linked_id, versionTags, newest_version)\n",
    "        VALUES (%s, %s, %s)\n",
    "        \"\"\"\n",
    "        version_tags_values = (\n",
    "            data.get(\"id\"),\n",
    "            json.dumps(version_tags),\n",
    "            biggest_version_tag\n",
    "        )\n",
    "\n",
    "        cur.execute(version_tags_query, version_tags_values)\n",
    "\n",
    "    conn.commit()\n",
    "    print(\"Data inserted successfully!\")\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    conn.rollback()\n",
    "    print(\"Error occurred while inserting data:\", e)\n",
    "\n",
    "finally:\n",
    "    cur.close()\n",
    "    conn.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "# insert into changes table\n",
    "import psycopg2\n",
    "import json\n",
    "import os\n",
    "\n",
    "connection_params = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5432\",\n",
    "    \"database\": \"issuesCheckpoint_Inkscape\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"Wuzhonghao0313!\"\n",
    "}\n",
    "\n",
    "json_directory = \"/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/issuesCheckpoint_Inkscape_split/split data/split link commits\"\n",
    "\n",
    "conn = psycopg2.connect(**connection_params)\n",
    "cur = conn.cursor()\n",
    "\n",
    "try:\n",
    "    for filename in os.listdir(json_directory):\n",
    "        filepath = os.path.join(json_directory, filename)\n",
    "        with open(filepath, \"r\", encoding=\"ascii\", errors=\"ignore\") as file:\n",
    "            try:\n",
    "                data = json.load(file)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error: Invalid JSON file: {filepath}\")\n",
    "                continue\n",
    "\n",
    "        changes = data.get(\"changes\", [])\n",
    "        for change in changes:\n",
    "            query = \"\"\"\n",
    "            INSERT INTO changes (linked_id, before, after)\n",
    "            VALUES (%s, %s, %s)\n",
    "            \"\"\"\n",
    "            values = (\n",
    "                data.get(\"id\"),\n",
    "                change.get(\"before\"),\n",
    "                change.get(\"after\")\n",
    "            )\n",
    "            cur.execute(query, values)\n",
    "\n",
    "    conn.commit()\n",
    "    print(\"Data inserted successfully!\")\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    conn.rollback()\n",
    "    print(\"Error occurred while inserting data:\", e)\n",
    "\n",
    "finally:\n",
    "    cur.close()\n",
    "    conn.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Deal with recovArOutput_Graphviz_ACDC"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split JSON files saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# split the json file\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Set the current working directory\n",
    "os.chdir('/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/recovArOutput_Graphviz')\n",
    "\n",
    "# Load the nested JSON file\n",
    "with open('recovArOutput_Graphviz_ACDC.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Create a directory to store the split JSON files\n",
    "output_directory = '/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/recovArOutput_Graphviz/recovArOutput_Graphviz_ACDC_split'\n",
    "\n",
    "for obj in data['decisions']:\n",
    "    # Extract the id and version fields\n",
    "    issue_id = obj[\"id\"]\n",
    "    version = obj[\"version\"]\n",
    "\n",
    "    # Create a filename based on the id and version\n",
    "    filename = f\"issue_{issue_id}_version_{version}.json\"\n",
    "\n",
    "    # Create the full file path\n",
    "    output_filepath = os.path.join(output_directory, filename)\n",
    "\n",
    "    # Write the object to a separate JSON file\n",
    "    with open(output_filepath, \"w\") as outfile:\n",
    "        json.dump(obj, outfile, indent=4)\n",
    "\n",
    "print('Split JSON files saved successfully.')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "# insert into json_with_link table, exclude versionTags and changes\n",
    "\n",
    "connection_params = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5432\",\n",
    "    \"database\": \"recovaroutput\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"Wuzhonghao0313!\"\n",
    "}\n",
    "\n",
    "json_directory = \"/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/recovArOutput_Graphviz/recovArOutput_Graphviz_ACDC_split\"\n",
    "\n",
    "conn = psycopg2.connect(**connection_params)\n",
    "cur = conn.cursor()\n",
    "\n",
    "try:\n",
    "    for filename in os.listdir(json_directory):\n",
    "            filepath = os.path.join(json_directory, filename)\n",
    "            with open(filepath, \"r\", encoding=\"ascii\", errors=\"ignore\") as file:\n",
    "                try:\n",
    "                    data = json.load(file)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Error: Invalid JSON file: {filepath}\")\n",
    "                    continue\n",
    "\n",
    "            query = \"\"\" INSERT INTO ACDC (id, version, addedElements, removedElements, description)\n",
    "            VALUES (%s, %s, %s, %s, %s)\n",
    "            \"\"\"\n",
    "            values = (\n",
    "                data.get(\"id\"),\n",
    "                data.get(\"version\"),\n",
    "                data.get(\"addedElements\"),\n",
    "                data.get(\"removedElements\"),\n",
    "                data.get(\"description\")\n",
    "            )\n",
    "\n",
    "            cur.execute(query, values)\n",
    "\n",
    "    conn.commit()\n",
    "    print(\"Data inserted successfully!\")\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    conn.rollback()\n",
    "    print(\"Error occurred while inserting data:\", e)\n",
    "\n",
    "finally:\n",
    "    cur.close()\n",
    "    conn.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split JSON files saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# split the json file\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Set the current working directory\n",
    "os.chdir('/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/recovArOutput_Graphviz')\n",
    "\n",
    "# Load the nested JSON file\n",
    "with open('recovArOutput_Graphviz_Arc.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Create a directory to store the split JSON files\n",
    "output_directory = '/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/recovArOutput_Graphviz/recovArOutput_Graphviz_Arc_split'\n",
    "\n",
    "for obj in data['decisions']:\n",
    "    # Extract the id and version fields\n",
    "    issue_id = obj[\"id\"]\n",
    "    version = obj[\"version\"]\n",
    "\n",
    "    # Create a filename based on the id and version\n",
    "    filename = f\"issue_{issue_id}_version_{version}.json\"\n",
    "\n",
    "    # Create the full file path\n",
    "    output_filepath = os.path.join(output_directory, filename)\n",
    "\n",
    "    # Write the object to a separate JSON file\n",
    "    with open(output_filepath, \"w\") as outfile:\n",
    "        json.dump(obj, outfile, indent=4)\n",
    "\n",
    "print('Split JSON files saved successfully.')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "# insert into json_with_link table, exclude versionTags and changes\n",
    "\n",
    "connection_params = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5432\",\n",
    "    \"database\": \"recovaroutput\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"Wuzhonghao0313!\"\n",
    "}\n",
    "\n",
    "json_directory = \"/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/recovArOutput_Graphviz/recovArOutput_Graphviz_Arc_split\"\n",
    "\n",
    "conn = psycopg2.connect(**connection_params)\n",
    "cur = conn.cursor()\n",
    "\n",
    "try:\n",
    "    for filename in os.listdir(json_directory):\n",
    "            filepath = os.path.join(json_directory, filename)\n",
    "            with open(filepath, \"r\", encoding=\"ascii\", errors=\"ignore\") as file:\n",
    "                try:\n",
    "                    data = json.load(file)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Error: Invalid JSON file: {filepath}\")\n",
    "                    continue\n",
    "\n",
    "            query = \"\"\" INSERT INTO arc (id, version, addedElements, removedElements, description)\n",
    "            VALUES (%s, %s, %s, %s, %s)\n",
    "            \"\"\"\n",
    "            values = (\n",
    "                data.get(\"id\"),\n",
    "                data.get(\"version\"),\n",
    "                data.get(\"addedElements\"),\n",
    "                data.get(\"removedElements\"),\n",
    "                data.get(\"description\")\n",
    "            )\n",
    "\n",
    "            cur.execute(query, values)\n",
    "\n",
    "    conn.commit()\n",
    "    print(\"Data inserted successfully!\")\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    conn.rollback()\n",
    "    print(\"Error occurred while inserting data:\", e)\n",
    "\n",
    "finally:\n",
    "    cur.close()\n",
    "    conn.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split JSON files saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# split the json file\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Set the current working directory\n",
    "os.chdir('/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/recovArOutput_Graphviz')\n",
    "\n",
    "# Load the nested JSON file\n",
    "with open('recovArOutput_Graphviz_Limbo.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Create a directory to store the split JSON files\n",
    "output_directory = '/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/recovArOutput_Graphviz/recovArOutput_Graphviz_Limbo_split'\n",
    "\n",
    "for obj in data['decisions']:\n",
    "    # Extract the id and version fields\n",
    "    issue_id = obj[\"id\"]\n",
    "    version = obj[\"version\"]\n",
    "\n",
    "    # Create a filename based on the id and version\n",
    "    filename = f\"issue_{issue_id}_version_{version}.json\"\n",
    "\n",
    "    # Create the full file path\n",
    "    output_filepath = os.path.join(output_directory, filename)\n",
    "\n",
    "    # Write the object to a separate JSON file\n",
    "    with open(output_filepath, \"w\") as outfile:\n",
    "        json.dump(obj, outfile, indent=4)\n",
    "\n",
    "print('Split JSON files saved successfully.')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "# insert into json_with_link table, exclude versionTags and changes\n",
    "\n",
    "connection_params = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5432\",\n",
    "    \"database\": \"recovaroutput\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"Wuzhonghao0313!\"\n",
    "}\n",
    "\n",
    "json_directory = \"/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/recovArOutput_Graphviz/recovArOutput_Graphviz_Limbo_split\"\n",
    "\n",
    "conn = psycopg2.connect(**connection_params)\n",
    "cur = conn.cursor()\n",
    "\n",
    "try:\n",
    "    for filename in os.listdir(json_directory):\n",
    "            filepath = os.path.join(json_directory, filename)\n",
    "            with open(filepath, \"r\", encoding=\"ascii\", errors=\"ignore\") as file:\n",
    "                try:\n",
    "                    data = json.load(file)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Error: Invalid JSON file: {filepath}\")\n",
    "                    continue\n",
    "\n",
    "            query = \"\"\" INSERT INTO limbo (id, version, addedElements, removedElements, description)\n",
    "            VALUES (%s, %s, %s, %s, %s)\n",
    "            \"\"\"\n",
    "            values = (\n",
    "                data.get(\"id\"),\n",
    "                data.get(\"version\"),\n",
    "                data.get(\"addedElements\"),\n",
    "                data.get(\"removedElements\"),\n",
    "                data.get(\"description\")\n",
    "            )\n",
    "\n",
    "            cur.execute(query, values)\n",
    "\n",
    "    conn.commit()\n",
    "    print(\"Data inserted successfully!\")\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    conn.rollback()\n",
    "    print(\"Error occurred while inserting data:\", e)\n",
    "\n",
    "finally:\n",
    "    cur.close()\n",
    "    conn.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split JSON files saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# split the json file\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Set the current working directory\n",
    "os.chdir('/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/recovArOutput_Graphviz')\n",
    "\n",
    "# Load the nested JSON file\n",
    "with open('recovArOutput_Graphviz_PKG.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Create a directory to store the split JSON files\n",
    "output_directory = '/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/recovArOutput_Graphviz/recovArOutput_Graphviz_PKG_split'\n",
    "\n",
    "for obj in data['decisions']:\n",
    "    # Extract the id and version fields\n",
    "    issue_id = obj[\"id\"]\n",
    "    version = obj[\"version\"]\n",
    "\n",
    "    # Create a filename based on the id and version\n",
    "    filename = f\"issue_{issue_id}_version_{version}.json\"\n",
    "\n",
    "    # Create the full file path\n",
    "    output_filepath = os.path.join(output_directory, filename)\n",
    "\n",
    "    # Write the object to a separate JSON file\n",
    "    with open(output_filepath, \"w\") as outfile:\n",
    "        json.dump(obj, outfile, indent=4)\n",
    "\n",
    "print('Split JSON files saved successfully.')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "# insert into json_with_link table, exclude versionTags and changes\n",
    "\n",
    "connection_params = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5432\",\n",
    "    \"database\": \"recovaroutput\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"Wuzhonghao0313!\"\n",
    "}\n",
    "\n",
    "json_directory = \"/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/recovArOutput_Graphviz/recovArOutput_Graphviz_PKG_split\"\n",
    "\n",
    "conn = psycopg2.connect(**connection_params)\n",
    "cur = conn.cursor()\n",
    "\n",
    "try:\n",
    "    for filename in os.listdir(json_directory):\n",
    "            filepath = os.path.join(json_directory, filename)\n",
    "            with open(filepath, \"r\", encoding=\"ascii\", errors=\"ignore\") as file:\n",
    "                try:\n",
    "                    data = json.load(file)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Error: Invalid JSON file: {filepath}\")\n",
    "                    continue\n",
    "\n",
    "            query = \"\"\" INSERT INTO pkg (id, version, addedElements, removedElements, description)\n",
    "            VALUES (%s, %s, %s, %s, %s)\n",
    "            \"\"\"\n",
    "            values = (\n",
    "                data.get(\"id\"),\n",
    "                data.get(\"version\"),\n",
    "                data.get(\"addedElements\"),\n",
    "                data.get(\"removedElements\"),\n",
    "                data.get(\"description\")\n",
    "            )\n",
    "\n",
    "            cur.execute(query, values)\n",
    "\n",
    "    conn.commit()\n",
    "    print(\"Data inserted successfully!\")\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    conn.rollback()\n",
    "    print(\"Error occurred while inserting data:\", e)\n",
    "\n",
    "finally:\n",
    "    cur.close()\n",
    "    conn.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Deal with project_Graphviz_decision_mentions\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split JSON files saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# split the json file\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Set the current working directory\n",
    "os.chdir('/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data')\n",
    "\n",
    "# Load the nested JSON file\n",
    "with open('project_Graphviz_decision_mentions.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Create a directory to store the split JSON files\n",
    "output_directory = '/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/decision_mention_split'\n",
    "\n",
    "for item in data:\n",
    "    issue_id = int(list(item.keys())[0])  # extract the issue_id\n",
    "    json_str = list(item.values())[0]\n",
    "\n",
    "    try:\n",
    "        json_obj = json.loads(json_str)\n",
    "        id = json_obj.get(\"id\")\n",
    "        filename = os.path.join(output_directory, f\"{issue_id}_{id}.json\")\n",
    "\n",
    "        with open(filename, 'w') as outfile:\n",
    "            json.dump(json_obj, outfile, indent=4)\n",
    "\n",
    "        # print(f'Saved {filename}')\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f'Error decoding JSON: {e}')\n",
    "\n",
    "print('Split JSON files saved successfully.')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "# insert into ids table\n",
    "\n",
    "connection_params = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5432\",\n",
    "    \"database\": \"project_Graphviz_decision_mentions\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"Wuzhonghao0313!\"\n",
    "}\n",
    "\n",
    "json_directory = \"/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/decision_mention_split\"\n",
    "\n",
    "conn = psycopg2.connect(**connection_params)\n",
    "cur = conn.cursor()\n",
    "\n",
    "try:\n",
    "    for filename in os.listdir(json_directory):\n",
    "            filepath = os.path.join(json_directory, filename)\n",
    "            with open(filepath, \"r\", encoding=\"ascii\", errors=\"ignore\") as file:\n",
    "                try:\n",
    "                    data = json.load(file)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Error: Invalid JSON file: {filepath}\")\n",
    "                    continue\n",
    "\n",
    "            # Split the filename by underscore\n",
    "            ids = filename.split('_')\n",
    "            # Extract the primary ID and linked ID\n",
    "            issue_id = ids[0]\n",
    "\n",
    "            query = \"\"\" INSERT INTO ids (issue_id, id)\n",
    "            VALUES (%s, %s)\n",
    "            \"\"\"\n",
    "            values = (\n",
    "                issue_id,\n",
    "                data.get(\"id\")\n",
    "            )\n",
    "\n",
    "            cur.execute(query, values)\n",
    "\n",
    "    conn.commit()\n",
    "    print(\"Data inserted successfully!\")\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    conn.rollback()\n",
    "    print(\"Error occurred while inserting data:\", e)\n",
    "\n",
    "finally:\n",
    "    cur.close()\n",
    "    conn.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "# insert into ids table\n",
    "\n",
    "connection_params = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5432\",\n",
    "    \"database\": \"project_Graphviz_decision_mentions\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"Wuzhonghao0313!\"\n",
    "}\n",
    "\n",
    "json_directory = \"/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/decision_mention_split\"\n",
    "\n",
    "conn = psycopg2.connect(**connection_params)\n",
    "cur = conn.cursor()\n",
    "\n",
    "try:\n",
    "    for filename in os.listdir(json_directory):\n",
    "            filepath = os.path.join(json_directory, filename)\n",
    "            with open(filepath, \"r\", encoding=\"ascii\", errors=\"ignore\") as file:\n",
    "                try:\n",
    "                    data = json.load(file)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Error: Invalid JSON file: {filepath}\")\n",
    "                    continue\n",
    "\n",
    "            # Extract the timestamp values and handle empty strings\n",
    "            created_at = data.get(\"created_at\") or None\n",
    "            updated_at = data.get(\"updated_at\") or None\n",
    "\n",
    "            # Remove the 'Z' character from the timestamp strings\n",
    "            created_at = created_at.rstrip('Z') if created_at else None\n",
    "            updated_at = updated_at.rstrip('Z') if updated_at else None\n",
    "\n",
    "            query = \"\"\" INSERT INTO decisions (id, type, body, attachment, author, created_at, updated_at, system, noteable_id, noteable_type, project_id, resolvable, confidential, internal, noteable_iid)\n",
    "            VALUES(%s, %s, %s, %s, %s, TO_TIMESTAMP(%s, 'YYYY-MM-DDTHH24:MI:SS.US'), TO_TIMESTAMP(%s, 'YYYY-MM-DDTHH24:MI:SS.US'), %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "\n",
    "            \"\"\"\n",
    "            values = (\n",
    "                data.get(\"id\"),\n",
    "                data.get(\"type\"),\n",
    "                data.get(\"body\"),\n",
    "                data.get(\"attachment\"),\n",
    "                json.dumps(data.get(\"author\")),\n",
    "                created_at,\n",
    "                updated_at,\n",
    "                data.get(\"system\"),\n",
    "                data.get(\"noteable_id\"),\n",
    "                data.get(\"noteable_type\"),\n",
    "                data.get(\"project_id\"),\n",
    "                data.get(\"resolvable\"),\n",
    "                data.get(\"confidential\"),\n",
    "                data.get(\"internal\"),\n",
    "                data.get(\"noteable_iid\")\n",
    "            )\n",
    "\n",
    "            cur.execute(query, values)\n",
    "\n",
    "    conn.commit()\n",
    "    print(\"Data inserted successfully!\")\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    conn.rollback()\n",
    "    print(\"Error occurred while inserting data:\", e)\n",
    "\n",
    "finally:\n",
    "    cur.close()\n",
    "    conn.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}