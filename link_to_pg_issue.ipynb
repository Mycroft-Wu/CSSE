{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import psycopg2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# split the file into with_link and no_link tables\n",
    "import json\n",
    "import os\n",
    "\n",
    "input_directory = \"/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data\"\n",
    "output_directory = \"/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/split data\"\n",
    "\n",
    "for filename in os.listdir(input_directory):\n",
    "    if filename.startswith(\"issue_\") and filename.endswith(\".json\"):\n",
    "        input_filepath = os.path.join(input_directory, filename)\n",
    "        output_filepath_no_links = os.path.join(output_directory, f\"{filename}_no_links.json\")\n",
    "        output_filepath_with_links = os.path.join(output_directory, f\"{filename}_with_links.json\")\n",
    "\n",
    "        with open(input_filepath, \"r\") as input_file:\n",
    "            data = json.load(input_file)\n",
    "\n",
    "        # Extract the \"linkedCommits\" and remove it from the original data\n",
    "        linked_commits = data[\"record\"].pop(\"linkedCommits\", [])\n",
    "\n",
    "        # Write the data without \"linkedCommits\" to a separate file\n",
    "        with open(output_filepath_no_links, \"w\") as output_file:\n",
    "            json.dump(data, output_file, indent=4)\n",
    "\n",
    "        # Create a new dictionary with \"linkedCommits\" and \"id\" as primary key\n",
    "        new_data = {\n",
    "            \"id\": data[\"id\"],\n",
    "            \"linkedCommits\": linked_commits\n",
    "        }\n",
    "\n",
    "        # Write the data with \"linkedCommits\" and \"id\" to a separate file\n",
    "        with open(output_filepath_with_links, \"w\") as output_file:\n",
    "            json.dump(new_data, output_file, indent=4)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred while inserting data: duplicate key value violates unique constraint \"json_no_links_pkey\"\n",
      "DETAIL:  Key (id)=(1976) already exists.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# insert into json_no_link table\n",
    "\n",
    "import os\n",
    "import json\n",
    "import psycopg2\n",
    "\n",
    "connection_params = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5432\",\n",
    "    \"database\": \"issuesCheckpoint_Graphviz\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"Wuzhonghao0313!\"\n",
    "}\n",
    "\n",
    "json_directory = \"/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/split data\"\n",
    "\n",
    "conn = psycopg2.connect(**connection_params)\n",
    "cur = conn.cursor()\n",
    "\n",
    "try:\n",
    "    for filename in os.listdir(json_directory):\n",
    "        if filename.endswith(\"_no_links.json\"):\n",
    "            filepath = os.path.join(json_directory, filename)\n",
    "            with open(filepath, \"r\") as file:\n",
    "                data = json.load(file)\n",
    "\n",
    "            id = int(filename.split(\"_\")[1].split(\".\")[0])\n",
    "            record = data[\"record\"]\n",
    "\n",
    "            # Extract the timestamp values and handle empty strings\n",
    "            created = record.get(\"created\") or None\n",
    "            resolved = record.get(\"resolved\") or None\n",
    "\n",
    "            # Remove the 'Z' character from the timestamp strings\n",
    "            created = created.rstrip('Z') if created else None\n",
    "            resolved = resolved.rstrip('Z') if resolved else None\n",
    "\n",
    "            query = \"\"\"\n",
    "            INSERT INTO json_no_links (id, url, summary, description, type, priority, status, resolution, created, resolved, labels, versions, fixVersions, comments)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, TO_TIMESTAMP(%s, 'YYYY-MM-DDTHH24:MI:SS.US'), TO_TIMESTAMP(%s, 'YYYY-MM-DDTHH24:MI:SS.US'), %s, %s, %s, %s)\n",
    "            \"\"\"\n",
    "            values = (\n",
    "                id,\n",
    "                record.get(\"url\"),\n",
    "                record.get(\"summary\"),\n",
    "                record.get(\"description\"),\n",
    "                record.get(\"type\"),\n",
    "                record.get(\"priority\"),\n",
    "                record.get(\"status\"),\n",
    "                record.get(\"resolution\"),\n",
    "                created,\n",
    "                resolved,\n",
    "                json.dumps(record.get(\"labels\")),\n",
    "                json.dumps(record.get(\"versions\")),\n",
    "                json.dumps(record.get(\"fixVersions\")),\n",
    "                json.dumps(record.get(\"comments\"))\n",
    "            )\n",
    "\n",
    "            cur.execute(query, values)\n",
    "\n",
    "    conn.commit()\n",
    "    print(\"Data inserted successfully!\")\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    conn.rollback()\n",
    "    print(\"Error occurred while inserting data:\", e)\n",
    "\n",
    "finally:\n",
    "    cur.close()\n",
    "    conn.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# split the with_link json files\n",
    "import json\n",
    "import os\n",
    "\n",
    "def split_json_files(filename, output_directory):\n",
    "    with open(filename, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Iterate over the linked commits and create separate files\n",
    "    for index, commit in enumerate(data['linkedCommits']):\n",
    "        primary_id = data['id']\n",
    "        linked_id = commit['id']\n",
    "\n",
    "        # Create the output file name using both primary and linked IDs\n",
    "        output_filename = f\"{primary_id}_{linked_id}.json\"\n",
    "        output_filepath = os.path.join(output_directory, output_filename)\n",
    "\n",
    "        # Write the linked commit data to a separate JSON file\n",
    "        with open(output_filepath, 'w') as output_file:\n",
    "            json.dump(commit, output_file, indent=4)\n",
    "\n",
    "# Specify the input directory\n",
    "input_directory = '/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/split data'\n",
    "# Specify the output directory\n",
    "output_directory = '/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/split data/split link commits'\n",
    "\n",
    "# Iterate over the files in the input directory\n",
    "for filename in os.listdir(input_directory):\n",
    "    if filename.startswith(\"issue_\") and filename.endswith(\"json_with_links.json\"):\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(input_directory, filename)\n",
    "        # Split the JSON file and save the linked commits to the output directory\n",
    "        split_json_files(file_path, output_directory)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The encoding of the JSON file is: ascii\n"
     ]
    }
   ],
   "source": [
    "import chardet\n",
    "import json\n",
    "\n",
    "def detect_encoding(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        raw_data = file.read()\n",
    "        result = chardet.detect(raw_data)\n",
    "        encoding = result['encoding']\n",
    "        return encoding\n",
    "\n",
    "# Provide the path to your JSON file\n",
    "json_file_path = '/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/split data/split link commits/14_2577.json'\n",
    "\n",
    "# Detect the encoding\n",
    "encoding = detect_encoding(json_file_path)\n",
    "\n",
    "# Print the detected encoding\n",
    "print(f\"The encoding of the JSON file is: {encoding}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Invalid JSON file: /Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/split data/split link commits/.DS_Store\n",
      "Data inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "# insert into json_with_link table, exclude versionTags and changes\n",
    "\n",
    "connection_params = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5432\",\n",
    "    \"database\": \"issuesCheckpoint_Graphviz\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"Wuzhonghao0313!\"\n",
    "}\n",
    "\n",
    "json_directory = \"/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/split data/split link commits\"\n",
    "\n",
    "conn = psycopg2.connect(**connection_params)\n",
    "cur = conn.cursor()\n",
    "\n",
    "try:\n",
    "    for filename in os.listdir(json_directory):\n",
    "            filepath = os.path.join(json_directory, filename)\n",
    "            with open(filepath, \"r\", encoding=\"ascii\", errors=\"ignore\") as file:\n",
    "                try:\n",
    "                    data = json.load(file)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Error: Invalid JSON file: {filepath}\")\n",
    "                    continue\n",
    "\n",
    "            # Split the filename by underscore\n",
    "            ids = filename.split('_')\n",
    "            # Extract the primary ID and linked ID\n",
    "            primary_id = ids[0]\n",
    "\n",
    "            # Extract the timestamp values and handle empty strings\n",
    "            created = data.get(\"created\") or None\n",
    "\n",
    "            # Remove the 'Z' character from the timestamp strings\n",
    "            created = created.rstrip('Z') if created else None\n",
    "\n",
    "            query = \"\"\" INSERT INTO json_with_links (id, linked_id, summary, description, status, url, sha, created, merged, labels)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, TO_TIMESTAMP(%s, 'YYYY-MM-DDTHH24:MI:SS.US'),  %s, %s)\n",
    "            \"\"\"\n",
    "            values = (\n",
    "                primary_id,\n",
    "                data.get(\"id\"),\n",
    "                data.get(\"summary\"),\n",
    "                data.get(\"description\"),\n",
    "                data.get(\"status\"),\n",
    "                data.get(\"url\"),\n",
    "                data.get(\"sha\"),\n",
    "                created,\n",
    "                data.get(\"merged\"),\n",
    "                json.dumps(data.get(\"labels\"))\n",
    "            )\n",
    "\n",
    "            cur.execute(query, values)\n",
    "\n",
    "    conn.commit()\n",
    "    print(\"Data inserted successfully!\")\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    conn.rollback()\n",
    "    print(\"Error occurred while inserting data:\", e)\n",
    "\n",
    "finally:\n",
    "    cur.close()\n",
    "    conn.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Invalid JSON file: /Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/split data/split link commits/.DS_Store\n",
      "Data inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "# insert into versionTags table, in total 3 columns\n",
    "import json\n",
    "import psycopg2\n",
    "import os\n",
    "\n",
    "connection_params = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5432\",\n",
    "    \"database\": \"issuesCheckpoint_Graphviz\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"Wuzhonghao0313!\"\n",
    "}\n",
    "\n",
    "json_directory = \"/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/split data/split link commits\"\n",
    "\n",
    "conn = psycopg2.connect(**connection_params)\n",
    "cur = conn.cursor()\n",
    "\n",
    "try:\n",
    "    for filename in os.listdir(json_directory):\n",
    "        filepath = os.path.join(json_directory, filename)\n",
    "        with open(filepath, \"r\", encoding=\"ascii\", errors=\"ignore\") as file:\n",
    "            try:\n",
    "                data = json.load(file)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error: Invalid JSON file: {filepath}\")\n",
    "                continue\n",
    "\n",
    "        # Extract versionTags and find the biggest versionTag\n",
    "        version_tags = data.get(\"versionTags\") or []\n",
    "        biggest_version_tag = max(version_tags) if version_tags else None\n",
    "\n",
    "        # Insert data into the new table for versionTags\n",
    "        version_tags_query = \"\"\"\n",
    "        INSERT INTO versionTags (linked_id, versionTags, newest_version)\n",
    "        VALUES (%s, %s, %s)\n",
    "        \"\"\"\n",
    "        version_tags_values = (\n",
    "            data.get(\"id\"),\n",
    "            json.dumps(version_tags),\n",
    "            biggest_version_tag\n",
    "        )\n",
    "\n",
    "        cur.execute(version_tags_query, version_tags_values)\n",
    "\n",
    "    conn.commit()\n",
    "    print(\"Data inserted successfully!\")\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    conn.rollback()\n",
    "    print(\"Error occurred while inserting data:\", e)\n",
    "\n",
    "finally:\n",
    "    cur.close()\n",
    "    conn.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Invalid JSON file: /Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/split data/split link commits/.DS_Store\n",
      "Data inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "# insert into changes table\n",
    "import psycopg2\n",
    "import json\n",
    "import os\n",
    "\n",
    "connection_params = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5432\",\n",
    "    \"database\": \"issuesCheckpoint_Graphviz\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"Wuzhonghao0313!\"\n",
    "}\n",
    "\n",
    "json_directory = \"/Users/wuzhonghao/Desktop/2023 Spring/2023 Summer/data/split data/split link commits\"\n",
    "\n",
    "conn = psycopg2.connect(**connection_params)\n",
    "cur = conn.cursor()\n",
    "\n",
    "try:\n",
    "    for filename in os.listdir(json_directory):\n",
    "        filepath = os.path.join(json_directory, filename)\n",
    "        with open(filepath, \"r\", encoding=\"ascii\", errors=\"ignore\") as file:\n",
    "            try:\n",
    "                data = json.load(file)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error: Invalid JSON file: {filepath}\")\n",
    "                continue\n",
    "\n",
    "        changes = data.get(\"changes\", [])\n",
    "        for change in changes:\n",
    "            query = \"\"\"\n",
    "            INSERT INTO changes (linked_id, before, after)\n",
    "            VALUES (%s, %s, %s)\n",
    "            \"\"\"\n",
    "            values = (\n",
    "                data.get(\"id\"),\n",
    "                change.get(\"before\"),\n",
    "                change.get(\"after\")\n",
    "            )\n",
    "            cur.execute(query, values)\n",
    "\n",
    "    conn.commit()\n",
    "    print(\"Data inserted successfully!\")\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    conn.rollback()\n",
    "    print(\"Error occurred while inserting data:\", e)\n",
    "\n",
    "finally:\n",
    "    cur.close()\n",
    "    conn.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}